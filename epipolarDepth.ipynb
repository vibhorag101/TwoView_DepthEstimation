{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to increase illumination of the two images img1 and img2 using opencv for better results in some cases\n",
    "def increaseillumination(img1, img2, i):\n",
    "    img1 = cv.convertScaleAbs(img1, alpha=1.5, beta=0)\n",
    "    img2 = cv.convertScaleAbs(img2, alpha=1.5, beta=0)\n",
    "    #uncomment the code if you want to display the illuminated images\n",
    "    #plt.figure(figsize=(10,10))\n",
    "    #plt.subplot(1,2,1)\n",
    "    #plt.imshow(img1, cmap='gray')\n",
    "    #plt.subplot(1,2,2)\n",
    "    #plt.imshow(img2, cmap='gray')\n",
    "    #plt.show()\n",
    "    #uncomment the code if you want to save the illuminated images seprately\n",
    "    cv.imwrite('epipolarImages/'+str(i+1)+'_illumination.jpg', img1)\n",
    "    cv.imwrite('epipolarImages/'+str(i+2)+'_illumination.jpg', img2)\n",
    "    return img1, img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def siftkeypointsdetection(img1, img2):\n",
    "    sift = cv.SIFT_create()\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "    return kp1, kp2, des1, des2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize keypoints detected by SIFT\n",
    "def visualizeKeypoints(img1, img2, kp1, kp2):\n",
    "    img1_kp = cv.drawKeypoints(img1, kp1, None, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    img2_kp = cv.drawKeypoints(img2, kp2, None, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    parameter2 = (0,0)\n",
    "    #resize the images before displaying them\n",
    "    imgSift1 = cv.resize(img1_kp, parameter2, fx=0.2, fy=0.2)\n",
    "    imgSift2 = cv.resize(img2_kp, parameter2, fx=0.2, fy=0.2)\n",
    "    #showig any 1 of the two images for keypoints detection\n",
    "    cv.imshow('SIFT Keypoints', imgSift1)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing function to calculate swift matches using FLANN index\n",
    "def flannmatches(des1, des2):\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "    search_params = dict(checks=50)\n",
    "    flann = cv.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(des1, des2, k=2)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing function to implement brute force matching\n",
    "def bruteforcematches(des1, des2):\n",
    "    bf = cv.BFMatcher()\n",
    "    matches = bf.knnMatch(des1,des2,k=2)\n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swiftmatching(des1, des2, typeofmatcher, kp1, kp2):\n",
    "    if(typeofmatcher == 'flann'):\n",
    "        matches = flannmatches(des1, des2)\n",
    "    elif(typeofmatcher == 'bruteforce'):\n",
    "        matches = bruteforcematches(des1, des2)\n",
    "    else:\n",
    "        print('Invalid matcher type')\n",
    "    matchesMask = [[0, 0] for i in range(len(matches))]\n",
    "    good = []\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "    for i, (m, n) in enumerate(matches):\n",
    "        if m.distance < 0.65*n.distance:\n",
    "            matchesMask[i] = [1, 0]\n",
    "            good.append(m)\n",
    "            pts2.append(kp2[m.trainIdx].pt)\n",
    "            pts1.append(kp1[m.queryIdx].pt)\n",
    "    return matches, matchesMask, good, pts1, pts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize good matches found using swift between the two images\n",
    "def visualizeMatches(img1, img2, kp1, kp2, good, matchesMask, matches):\n",
    "    img3 = cv.drawMatchesKnn(\n",
    "    img1, kp1, img2, kp2, matches, None, matchesMask=matchesMask, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    img3 = cv.resize(img3, (0, 0), fx=0.2, fy=0.2)\n",
    "    cv.imshow(\"SIFT Matches\", img3)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for selecting only inlier matches and hence updating the points array\n",
    "def selectinlier(pts1,pts2,inliers):\n",
    "    pts1 = pts1[inliers.ravel() == 1]\n",
    "    pts2 = pts2[inliers.ravel() == 1]\n",
    "    return pts1, pts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to select inliers points using RANSAC algorithm and finding fundamental matrix\n",
    "def findfundamentalmatrix(pts1, pts2):\n",
    "    pts1 = np.int32(pts1)\n",
    "    pts2 = np.int32(pts2)\n",
    "    fundamental_matrix, inliers = cv.findFundamentalMat(pts1, pts2, cv.FM_RANSAC)\n",
    "    return pts1, pts2, fundamental_matrix, inliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawlines(img1src, img2src, lines, pts1src, pts2src):\n",
    "    #img1 - image on which we draw the epilines for the points in img2\n",
    "    r = img1src.shape[0]\n",
    "    c = img1src.shape[1]\n",
    "    img1color = cv.cvtColor(img1src, cv.COLOR_GRAY2BGR)\n",
    "    img2color = cv.cvtColor(img2src, cv.COLOR_GRAY2BGR)\n",
    "    for r, pt1, pt2 in zip(lines, pts1src, pts2src):\n",
    "        color = tuple(np.random.randint(0, 255, 3).tolist())\n",
    "        parameter1 = (0, -r[2]/r[1])\n",
    "        parameter2 = (c, -(r[2]+r[0]*c)/r[1])\n",
    "        x0, y0 = map(int, parameter1)\n",
    "        x1, y1 = map(int, parameter2)\n",
    "        img1color = cv.line(img1color, (x0, y0), (x1, y1), color, 1)\n",
    "        img1color = cv.circle(img1color, tuple(pt1), 5, color, -1)\n",
    "        img2color = cv.circle(img2color, tuple(pt2), 5, color, -1)\n",
    "    return img1color, img2color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to plot epilines on the two images\n",
    "def plotepilines(img1, img2, pts1, pts2, fundamental_matrix):\n",
    "    plt.subplot(121), plt.imshow(img1)\n",
    "    plt.subplot(122), plt.imshow(img2)\n",
    "    plt.suptitle('Epilines in both images')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to draw epilines in both images and display them side by side\n",
    "def drawepilines(img1, img2, pts1, pts2, fundamental_matrix):\n",
    "    lines1 = cv.computeCorrespondEpilines(\n",
    "    pts2.reshape(-1, 1, 2), 2, fundamental_matrix)\n",
    "    lines1 = lines1.reshape(-1, 3)\n",
    "    img3, img4 = drawlines(img1, img2, lines1, pts1, pts2)\n",
    "    lines2 = cv.computeCorrespondEpilines(\n",
    "    pts1.reshape(-1, 1, 2), 1, fundamental_matrix)\n",
    "    lines2 = lines2.reshape(-1, 3)\n",
    "    img5, img6 = drawlines(img2, img1, lines2, pts2, pts1)\n",
    "    plotepilines(img3, img5, pts1, pts2, fundamental_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to do stereo rectification of the two images\n",
    "def stereorectification(img1, img2, pts1, pts2, fundamental_matrix):\n",
    "    h1 = img1.shape[0]\n",
    "    w1 = img1.shape[1]\n",
    "    h2 = img2.shape[0]\n",
    "    w2 = img2.shape[1]\n",
    "    _, H1, H2 = cv.stereoRectifyUncalibrated(\n",
    "    np.float32(pts1), np.float32(pts2), fundamental_matrix, imgSize=(w1, h1))\n",
    "    img1_rectified = cv.warpPerspective(img1, H1, (w1, h1))\n",
    "    img2_rectified = cv.warpPerspective(img2, H2, (w2, h2))\n",
    "    return img1_rectified, img2_rectified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to plot the rectified images side by side\n",
    "def plotrectifiedimages(img1_rectified, img2_rectified):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
    "    axes[0].imshow(img1_rectified, cmap=\"gray\")\n",
    "    axes[1].imshow(img2_rectified, cmap=\"gray\")\n",
    "    axes[0].axhline(250)\n",
    "    axes[1].axhline(250)\n",
    "    axes[0].axhline(450)\n",
    "    axes[1].axhline(450)\n",
    "    plt.suptitle(\"Rectified images\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find the depth map using SGBM algorithm and save it\n",
    "def depthmap(img1_rectified, img2_rectified, i):\n",
    "    block_size = 10\n",
    "    min_disp = -128\n",
    "    max_disp = 128\n",
    "    num_disp = max_disp - min_disp\n",
    "    uniquenessRatio = 15\n",
    "    speckleWindowSize = 200\n",
    "    speckleRange = 5\n",
    "    disp12MaxDiff = 5\n",
    "    stereo = cv.StereoSGBM_create(\n",
    "    minDisparity=min_disp,\n",
    "    numDisparities=num_disp,\n",
    "    blockSize=block_size,\n",
    "    uniquenessRatio=uniquenessRatio,\n",
    "    speckleWindowSize=speckleWindowSize,\n",
    "    speckleRange=speckleRange,\n",
    "    disp12MaxDiff=disp12MaxDiff,\n",
    "    P1=8 * 1 * block_size * block_size,\n",
    "    P2=32 * 1 * block_size * block_size,\n",
    "    )\n",
    "    disparity_SGBM = stereo.compute(img1_rectified, img2_rectified)\n",
    "    disparity_SGBM = cv.normalize(disparity_SGBM, disparity_SGBM, alpha=255,\n",
    "                                beta=0, norm_type=cv.NORM_MINMAX, dtype=cv.CV_8U)\n",
    "    disparity_SGBM = np.uint8(disparity_SGBM)\n",
    "    return disparity_SGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to plot the depth map obtained\n",
    "def plotdepthmap(disparity_SGBM, type,i):\n",
    "    plt.imshow(disparity_SGBM, cmap='plasma',)\n",
    "    if(type == '.png'):\n",
    "        plt.savefig('depthmapsmiddlebury/'+'depthmap'+str(i+1)+'.jpg')\n",
    "    else:\n",
    "        plt.savefig('depthmapsowndataset/'+'depthmap'+str(i+1)+'.png')\n",
    "    # plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) C:\\b\\abs_d8ltn27ay8\\croot\\opencv-suite_1676452046667\\work\\modules\\calib3d\\src\\stereosgbm.cpp:2212: error: (-215:Assertion failed) left.size() == right.size() && left.type() == right.type() && left.depth() == CV_8U in function 'cv::StereoSGBMImpl::compute'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Vibhor\\Desktop\\CV_Project\\epipolarDepth.ipynb Cell 18\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vibhor/Desktop/CV_Project/epipolarDepth.ipynb#X23sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m img1_rectified, img2_rectified \u001b[39m=\u001b[39m stereorectification(img1, img2, pts1, pts2, fundamental_matrix)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vibhor/Desktop/CV_Project/epipolarDepth.ipynb#X23sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m#plotrectifiedimages(img1_rectified, img2_rectified)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Vibhor/Desktop/CV_Project/epipolarDepth.ipynb#X23sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m disparity_SGBM \u001b[39m=\u001b[39m depthmap(img1_rectified, img2_rectified, i)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vibhor/Desktop/CV_Project/epipolarDepth.ipynb#X23sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m plotdepthmap(disparity_SGBM, \u001b[39mtype\u001b[39m,i)\n",
      "\u001b[1;32mc:\\Users\\Vibhor\\Desktop\\CV_Project\\epipolarDepth.ipynb Cell 18\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vibhor/Desktop/CV_Project/epipolarDepth.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m disp12MaxDiff \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vibhor/Desktop/CV_Project/epipolarDepth.ipynb#X23sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m stereo \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mStereoSGBM_create(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vibhor/Desktop/CV_Project/epipolarDepth.ipynb#X23sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m minDisparity\u001b[39m=\u001b[39mmin_disp,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vibhor/Desktop/CV_Project/epipolarDepth.ipynb#X23sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m numDisparities\u001b[39m=\u001b[39mnum_disp,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vibhor/Desktop/CV_Project/epipolarDepth.ipynb#X23sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m P2\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m \u001b[39m*\u001b[39m \u001b[39m1\u001b[39m \u001b[39m*\u001b[39m block_size \u001b[39m*\u001b[39m block_size,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vibhor/Desktop/CV_Project/epipolarDepth.ipynb#X23sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Vibhor/Desktop/CV_Project/epipolarDepth.ipynb#X23sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m disparity_SGBM \u001b[39m=\u001b[39m stereo\u001b[39m.\u001b[39;49mcompute(img1_rectified, img2_rectified)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vibhor/Desktop/CV_Project/epipolarDepth.ipynb#X23sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m disparity_SGBM \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mnormalize(disparity_SGBM, disparity_SGBM, alpha\u001b[39m=\u001b[39m\u001b[39m255\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vibhor/Desktop/CV_Project/epipolarDepth.ipynb#X23sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m                             beta\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, norm_type\u001b[39m=\u001b[39mcv\u001b[39m.\u001b[39mNORM_MINMAX, dtype\u001b[39m=\u001b[39mcv\u001b[39m.\u001b[39mCV_8U)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Vibhor/Desktop/CV_Project/epipolarDepth.ipynb#X23sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m disparity_SGBM \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39muint8(disparity_SGBM)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) C:\\b\\abs_d8ltn27ay8\\croot\\opencv-suite_1676452046667\\work\\modules\\calib3d\\src\\stereosgbm.cpp:2212: error: (-215:Assertion failed) left.size() == right.size() && left.type() == right.type() && left.depth() == CV_8U in function 'cv::StereoSGBMImpl::compute'\n"
     ]
    }
   ],
   "source": [
    "#declare path of folder where images are stored\n",
    "path = 'ourdataset/'\n",
    "type = \"\"\n",
    "length = len(glob.glob(path+'*'))\n",
    "if(path=='ourdataset/'):\n",
    "    type = \".jpg\"\n",
    "elif(path=='Middleburydataset/'):\n",
    "    type = \".png\"\n",
    "#obtaining the depth map for all images\n",
    "for i in range(length//2):\n",
    "    path1 = path+str(2*i+1)+type\n",
    "    path2 = path+str(2*i+2)+type\n",
    "    img1 = cv.imread(path1, cv.IMREAD_GRAYSCALE)\n",
    "    img2 = cv.imread(path2, cv.IMREAD_GRAYSCALE)\n",
    "    illuminationrequired = False\n",
    "    if(illuminationrequired):\n",
    "        img1, img2 = increaseillumination(img1, img2, i)\n",
    "    kp1, kp2, des1, des2 = siftkeypointsdetection(img1, img2)\n",
    "    #visualizeKeypoints(img1, img2, kp1, kp2)\n",
    "    typeofmatcher = 'bruteforce'\n",
    "    matches, matchesMask, good, pts1, pts2 = swiftmatching(des1, des2, typeofmatcher, kp1, kp2)\n",
    "    #visualizeMatches(img1, img2, kp1, kp2, good, matchesMask, matches)\n",
    "    pts1, pts2, fundamental_matrix, inliers = findfundamentalmatrix(pts1, pts2)\n",
    "    pts1, pts2 = selectinlier(pts1, pts2, inliers)\n",
    "    #drawepilines(img1, img2, pts1, pts2, fundamental_matrix)\n",
    "    img1_rectified, img2_rectified = stereorectification(img1, img2, pts1, pts2, fundamental_matrix)\n",
    "    #plotrectifiedimages(img1_rectified, img2_rectified)\n",
    "    disparity_SGBM = depthmap(img1_rectified, img2_rectified, i)\n",
    "    plotdepthmap(disparity_SGBM, type,i)\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
